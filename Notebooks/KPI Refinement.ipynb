{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aba9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52a39aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../project_dataset/extract_fees_data_analyst.csv')\n",
    "\n",
    "# Load the second CSV file\n",
    "df2 = pd.read_csv('../project_dataset/extract_cash request_data analyst.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6524f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.merge(df1, df2, left_on='cash_request_id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a01c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cash_request_df = df_ml[df_ml['cash_request_id'].isnull()]\n",
    "df_ml_clean = df_ml.dropna(subset=['cash_request_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756d9b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21057 entries, 0 to 21060\n",
      "Data columns (total 29 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id_x                        21057 non-null  int64  \n",
      " 1   cash_request_id             21057 non-null  float64\n",
      " 2   type                        21057 non-null  object \n",
      " 3   status_x                    21057 non-null  object \n",
      " 4   category                    2196 non-null   object \n",
      " 5   total_amount                21057 non-null  float64\n",
      " 6   reason                      21057 non-null  object \n",
      " 7   created_at_x                21057 non-null  object \n",
      " 8   updated_at_x                21057 non-null  object \n",
      " 9   paid_at                     15531 non-null  object \n",
      " 10  from_date                   7766 non-null   object \n",
      " 11  to_date                     7766 non-null   object \n",
      " 12  charge_moment               21057 non-null  object \n",
      " 13  id_y                        21057 non-null  float64\n",
      " 14  amount                      21057 non-null  float64\n",
      " 15  status_y                    21057 non-null  object \n",
      " 16  created_at_y                21057 non-null  object \n",
      " 17  updated_at_y                21057 non-null  object \n",
      " 18  user_id                     20151 non-null  float64\n",
      " 19  moderated_at                11284 non-null  object \n",
      " 20  deleted_account_id          906 non-null    float64\n",
      " 21  reimbursement_date          21057 non-null  object \n",
      " 22  cash_request_received_date  19763 non-null  object \n",
      " 23  money_back_date             19701 non-null  object \n",
      " 24  transfer_type               21057 non-null  object \n",
      " 25  send_at                     17570 non-null  object \n",
      " 26  recovery_status             6894 non-null   object \n",
      " 27  reco_creation               6894 non-null   object \n",
      " 28  reco_last_update            6894 non-null   object \n",
      "dtypes: float64(6), int64(1), object(22)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ml_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc2e9ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                              0\n",
       "cash_request_id                   0\n",
       "type                              0\n",
       "status_x                          0\n",
       "category                      18861\n",
       "total_amount                      0\n",
       "reason                            0\n",
       "created_at_x                      0\n",
       "updated_at_x                      0\n",
       "paid_at                        5526\n",
       "from_date                     13291\n",
       "to_date                       13291\n",
       "charge_moment                     0\n",
       "id_y                              0\n",
       "amount                            0\n",
       "status_y                          0\n",
       "created_at_y                      0\n",
       "updated_at_y                      0\n",
       "user_id                         906\n",
       "moderated_at                   9773\n",
       "deleted_account_id            20151\n",
       "reimbursement_date                0\n",
       "cash_request_received_date     1294\n",
       "money_back_date                1356\n",
       "transfer_type                     0\n",
       "send_at                        3487\n",
       "recovery_status               14163\n",
       "reco_creation                 14163\n",
       "reco_last_update              14163\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f85974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id_x  cash_request_id             type   status_x  \\\n",
      "4    11242          19350.0  instant_payment   accepted   \n",
      "75   16959          23989.0  instant_payment   accepted   \n",
      "106  14190          14924.0         incident   accepted   \n",
      "129  21176          15272.0         postpone  cancelled   \n",
      "133  11202          19372.0  instant_payment   accepted   \n",
      "\n",
      "                  category  total_amount                              reason  \\\n",
      "4                      NaN           5.0  Instant Payment Cash Request 19350   \n",
      "75                     NaN           5.0  Instant Payment Cash Request 23989   \n",
      "106  rejected_direct_debit           5.0               rejected direct debit   \n",
      "129                    NaN           5.0         Postpone Cash Request 15272   \n",
      "133                    NaN           5.0  Instant Payment Cash Request 19372   \n",
      "\n",
      "                      created_at_x                   updated_at_x  \\\n",
      "4    2020-10-06 08:20:17.170432+00  2020-10-13 14:25:03.267983+00   \n",
      "75   2020-10-24 10:22:47.111527+00  2020-10-24 10:22:47.111551+00   \n",
      "106  2020-10-16 23:48:55.379796+00  2020-10-16 23:48:55.379818+00   \n",
      "129  2020-11-01 23:01:27.934752+00  2020-11-01 23:01:27.934782+00   \n",
      "133  2020-10-06 06:34:48.209743+00  2020-10-13 14:25:10.240365+00   \n",
      "\n",
      "                           paid_at  ...                   moderated_at  \\\n",
      "4    2020-11-02 14:45:20.355598+00  ...  2020-10-06 08:20:15.587318+00   \n",
      "75   2020-11-16 02:57:54.271425+00  ...                            NaN   \n",
      "106  2020-11-07 05:10:51.711016+00  ...  2020-09-07 09:21:59.079802+00   \n",
      "129                            NaN  ...         2020-09-09 10:02:13+00   \n",
      "133  2020-11-03 05:10:00.146645+00  ...                            NaN   \n",
      "\n",
      "    deleted_account_id             reimbursement_date  \\\n",
      "4              19005.0         2020-10-30 11:00:00+00   \n",
      "75             29610.0  2020-11-03 10:22:40.194197+00   \n",
      "106            23059.0         2020-10-05 22:00:00+00   \n",
      "129            26653.0         2020-11-30 23:00:00+00   \n",
      "133            23893.0         2020-10-26 22:00:00+00   \n",
      "\n",
      "     cash_request_received_date                money_back_date transfer_type  \\\n",
      "4                    2020-10-09  2020-11-02 14:45:20.315696+00       instant   \n",
      "75                          NaN  2020-11-16 02:57:54.235926+00       instant   \n",
      "106                  2020-09-08         2020-11-05 23:00:00+00       instant   \n",
      "129                  2020-09-11         2020-12-02 23:00:00+00       instant   \n",
      "133                         NaN         2020-11-01 23:00:00+00       instant   \n",
      "\n",
      "                           send_at recovery_status  \\\n",
      "4    2020-10-13 00:40:23.983346+00       completed   \n",
      "75   2020-10-24 10:22:40.194197+00       completed   \n",
      "106  2020-09-14 09:19:12.982718+00       completed   \n",
      "129         2020-09-16 08:34:36+00             NaN   \n",
      "133  2020-10-13 06:34:12.617702+00             NaN   \n",
      "\n",
      "                     reco_creation               reco_last_update  \n",
      "4    2020-10-24 22:43:13.278707+00  2020-11-02 14:45:20.333109+00  \n",
      "75    2020-11-13 22:40:42.99552+00  2020-11-16 02:57:54.252045+00  \n",
      "106  2020-10-16 23:48:55.375844+00  2020-10-16 23:48:59.124042+00  \n",
      "129                            NaN                            NaN  \n",
      "133                            NaN                            NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "missing_user_id_rows = df_ml[df_ml['user_id'].isnull()]\n",
    "print(missing_user_id_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880a3b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-09-07 10:47:27.42315+00\n",
       "Name: created_at_x, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_clean['created_at_x'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b56898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml_clean['created_at_x'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3caad85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 21057\n",
      "  Cohort_by_month\n",
      "0         2020-09\n",
      "1         2020-09\n",
      "2         2020-10\n",
      "3         2020-10\n",
      "4         2020-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/ycxt4t395sz7rs26t5w0vjgc0000gn/T/ipykernel_19572/1419371860.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ml_clean['created_at_x'] = pd.to_datetime(df_ml_clean['created_at_x'])\n",
      "/var/folders/r6/ycxt4t395sz7rs26t5w0vjgc0000gn/T/ipykernel_19572/1419371860.py:8: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_ml_clean['Cohort_by_month'] = df_ml_clean['created_at_x'].dt.to_period('M')\n",
      "/var/folders/r6/ycxt4t395sz7rs26t5w0vjgc0000gn/T/ipykernel_19572/1419371860.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ml_clean['Cohort_by_month'] = df_ml_clean['created_at_x'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'created_at_x' is in datetime format\n",
    "df_ml_clean['created_at_x'] = pd.to_datetime(df_ml_clean['created_at_x'])\n",
    "\n",
    "# Create new column 'Cohort_by_month' containing only the month\n",
    "# You can format the date to show year and month if that is what's required\n",
    "df_ml_clean['Cohort_by_month'] = df_ml_clean['created_at_x'].dt.to_period('M')\n",
    "\n",
    "# Print the number of rows in the new column\n",
    "print(f\"Number of rows: {df_ml_clean.shape[0]}\")\n",
    "\n",
    "# Display the first 5 lines of the new column\n",
    "print(df_ml_clean[['Cohort_by_month']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e94b049",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_clean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Assuming df_clean is your main DataFrame and has columns like 'frequency', 'revenue', and 'incident_rate'\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Sample data for demonstration\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Calculate the correlation matrix\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m correlation_matrix = \u001b[43mdf_clean\u001b[49m[[\u001b[33m'\u001b[39m\u001b[33mfrequency\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrevenue\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mincident_rate\u001b[39m\u001b[33m'\u001b[39m]].corr()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Print the correlation matrix\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(correlation_matrix)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_clean' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df_clean is your main DataFrame and has columns like 'frequency', 'revenue', and 'incident_rate'\n",
    "\n",
    "# Sample data for demonstration\n",
    "# df_clean = pd.DataFrame({\n",
    "#     'frequency': [/* data */],\n",
    "#     'revenue': [/* data */],\n",
    "#     'incident_rate': [/* data */],\n",
    "#     # Add more relevant columns if needed\n",
    "# })\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_clean[['frequency', 'revenue', 'incident_rate']].corr()\n",
    "\n",
    "# Print the correlation matrix\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923deb29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
